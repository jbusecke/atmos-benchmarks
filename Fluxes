#!/usr/bin/env bash
################################################################################
# For *this task*, we get the the eddy heat flux and eddy momentum flux
# Use this to call successively call the different task1.x files, then time
# them, so we can compare their output. Consider automatically appending
# results to a markdown table or something
################################################################################
# Helper function
# We require a subshell to redirect 'time' for some reason; because it's weird
# builtin or something
name=$0
dir=$1 # directories where data is stored
[ -z "$dir" ] && echo "Error: Please enter location of NetCDFs for globbing/testing." && exit 1
! [ -d "$dir" ] && echo "Error: Directory \"$dir\" not found." && exit 1
output=logs/fluxes_${dir}_${HOSTNAME%%.*}.log # store here
header="| nlat | size | name | real (s) | user (s) | sys (s) |\n| --- | --- | --- | --- | --- | --- |\n"
rm $output 2>/dev/null
seconds() {
  # Convert time command output to raw seconds
  t=$1
  m=${t%m*}
  s=${t#*m}
  s=${s%.*}
  d=${t#*.} # decimal
  echo $((m*60 + s)).${d%s} # converts e.g. 1m35.23s to 85.23s
}
bench() {
  # Run time command
  # NOTE: Preserve stdout, because have Matlab print stuff after startup
  # is complete so we can get better estimate
  local real user sys
  res=$( (time "${@:2}" 2>/dev/null) 2>&1 )
  info="$(echo "${res%real*}" | xargs | tr -s ' ')"
  time="real ${res##*real}"
  array=($time)
  # Get result, tabulate it, add it to markdown file
  if [ -n "$info" ]; then # try to find the number, in seconds
    info="${info##*mathworks.com.}" # only way to remove startup....
    info="$(echo "$info" | sed 's/[^.0-9]//g')"
    real="$(seconds 0m${info%.1}s)" # weirdly, get extra '1' at end of string that is totally invisible before passing through sed
    printf "| $nlat | $size | $1 | **$real** | | |\n" >>$output
  else
    real=$(seconds ${array[1]})
    user=$(seconds ${array[3]})
    sys=$(seconds ${array[5]})
    printf "| $nlat | $size | $1 | **$real** | $user | $sys |\n" >>$output
  fi
  echo $1
  echo ${real}s
}

# Loop over datasets with different resolutions
datas=($dir/data*.nc)
counter=0
for data in ${datas[@]}; do
  # Header
  # NOTE: The 'disk usage' often very different from the 'apparent size'
  # ls -l; former depends on internals of how data is stored, and on Cheyenne,
  # ends up way bigger. See: https://unix.stackexchange.com/a/106278/112647
  # Explanation of why this happens: https://serverfault.com/a/290091/427991
  size=$(command du -h $data | xargs | cut -d' ' -f1)
  version=${data%.nc}
  version=${version##*_}
  nlat=${data#*N}
  nlat=$(printf '%.0f' ${nlat%T*})
  echo && echo "Dataset: $data ($size)"
  echo "Logfile: $output"
  printf "\n$header" >>$output # add header for each new file

  # Fortran method
  # NOTE: Assumes fortran installed with MacPorts, port install netcdf and port install netcdf-fortran
  gfortran -I/opt/local/include -L/opt/local/lib -lnetcdff -lnetcdf ${name}.f90 -o ${name}_f90
  bench "Fortran" ${name}_f90 $data
  rm ${name}_f90

  # Julia
  bench "Julia NCDatasets (compiled)" ./compiled/${name}_ncdatasets $data
  bench "Julia NetCDF (compiled)" ./compiled/${name}_netcdf $data
  # bench "Julia (naive)" julia -e 'push!(LOAD_PATH, "./"); using fluxes; fluxes.eddy_flux("'${name}'")' # will be ridiculously slow, don't bother

  # MATLAB
  # NOTE: nojvm very important, eliminates initial startup time
  # license="$(which matlab)"
  # license="${license%bin*}/licenses/license.dat"
  bench "MATLAB (no startup)" matlab -nojvm -nodisplay -r \
    "filename='${data}'; tic; fluxes; toc; disp(' '); exit"

  # Python with NetCDF4
  bench "Python netCDF4" python ${name}_nc4.py $data 0

  # Python with xarray method
  bench "XArray without dask" python ${name}_xarray.py $data 0

  # Python with xarray and Dask chunking by 2D slice
  if [ $dir == 1lev ]; then
    bench "XArray 1000 step chunks" python ${name}_xarray.py $data 1000
    # bench "XArray 200 step chunks"  python ${name}_xarray.py $data 200
    bench "XArray 100 step chunks" python ${name}_xarray.py $data 100
    # bench "XArray 50 step chunks"   python ${name}_xarray.py $data 50
    # bench "XArray 20 step chunks"   python ${name}_xarray.py $data 20
    bench "XArray 10 step chunks" python ${name}_xarray.py $data 20
  elif [ $dir == 60lev ]; then
    bench "XArray 200 step chunks" python ${name}_xarray.py $data 200
    # bench "XArray 50 step chunks"  python ${name}_xarray.py $data 50
    bench "XArray 20 step chunks" python ${name}_xarray.py $data 20
    # bench "XArray 10 step chunks"  python ${name}_xarray.py $data 10
    # bench "XArray 5 step chunks"   python ${name}_xarray.py $data 5
    bench "XArray 2 step chunks" python ${name}_xarray.py $data 2
    # bench "XArray 1 step chunks"   python ${name}_xarray.py $data 1
  else
    echo "Error: Unknown chunk combos for sample data in dir \"$dir\"."
    exit 1
  fi

  # CDO method
  # NOTE: On mac just run with serial IO
  # NOTE: Serial IO turned out to be really small difference
  bench "CDO" ${name}.cdo $data
  # bench "CDO no expr" ${name}_stupid.cdo $data
  # bench "CDO + serial IO" ${name}_stupid.cdo $data '-L'

  # NCL method
  # NOTE: NCL needs special dyld library path but so does brew, screws up
  # Homebrew if we set it, so set it locally
  export DYLD_LIBRARY_PATH="/usr/local/lib/gcc/4.9"
  bench "NCL" ncl -Q -n "filename=\"$data\"" "large=\"0\"" ${name}.ncl
  # bench "NCL + LargeFile" ncl -Q -n "filename=\"$data\"" "large=\"1\"" ${name}.ncl
  export DYLD_LIBRARY_PATH=""

  # NCO method with NCAP
  # Add options for handling large files; see: http://nco.sourceforge.net/nco.html#Temporary-Output-Files
  # No need to do both; we just need to 'open' or 'create' in RAM to prevent
  # issues with overwrites (2nd example). In this case we aren't writing to the
  # same file so we don't need to worry about those options.
  # NOTE: Turned out no tmp file made pretty much zero difference
  bench "NCO" ${name}.nco $data
  # bench "NCO + no tmp file" ${name}.nco $data --no_tmp_fl
  # bench "NCO + open in RAM" ${name}.nco $data --open_ram --no_tmp_fl
  # bench "NCO + create in RAM" ${name}.nco $data --create_ram --no_tmp_fl

done
