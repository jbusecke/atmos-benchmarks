#!/usr/bin/env bash
#------------------------------------------------------------------------------#
# Isentropic surface interpolation as function of file size
#------------------------------------------------------------------------------#
# Helper function
# We require a subshell to redirect 'time' for some reason; because it's weird
# builtin or something
name=$(echo $0 | tr [A-Z] [a-z])
dir=$1 # directories where data is stored
[ -z "$dir" ] && echo "Error: Please enter location of NetCDFs for globbing/testing." && exit 1
! [ -d "$dir" ] && echo "Error: Directory \"$dir\" not found." && exit 1
output=$dir/${name}_${HOSTNAME%%.*}.log # store here
header="| nlat | size (version) | name | real (s) | user (s) | sys (s) |\n| --- | --- | --- | --- | --- | --- |\n"
echo "Log: $output"
rm $output 2>/dev/null
seconds() {
  # Convert time command output to raw seconds
  m=${1%m*}
  s=${1#*m}
  s=${s%.*}
  t=${1#*.} # tail
  echo "$((m*60 + s)).${t%s}" # converts e.g. 1m35.23s to 85.23s
}
bench() {
  # Run time command
  # NOTE: Must be in a subshell, time is a special bash builtin that doesn't
  # print to 'stdout' *or* 'stderr'
  err=false
  res="$( (time ${@:2}) 2>&1 )"
  [ $? -ne 0 ] && err=true
  echo "$res" | grep "^fatal:" &>/dev/null && err=true
  $err && echo "Error: Bad exit code." && echo "$res" | sed 's/[[:space:]]*real[[:space:]]*.*//g' && return 1
  # $err && echo "$1 Error: Bad exit code." && return 1
  # Optionally print warnings or other messages
  # res="$(echo "$res" | grep -v Warning)" # ignore python warnings
  nline=$(wc -l <<< "$res")
  ts=($(tail -n 3 <<< "$res"))
  if [ $nline -gt 4 ]; then # empty line, plus sys, real, user time lines
    other="$(head -n $((nline - 4)) <<< "$res")"
    # echo "Lengh of warning messages: $(wc -l <<< "$other")"
    echo "Messages:" && echo "$other"
  fi
  # Get result, tabulate it, add it to markdown file
  real=$(seconds ${ts[1]})
  user=$(seconds ${ts[3]})
  sys=$(seconds ${ts[5]})
  echo "$1 time: ${real}s"
  printf "| $nlat | $size ($version) | $1 | **$real** | $user | $sys |\n" >>$output
}
ncl_parallel() {
  local name1 name2 glob1 glob2 ts t
  name1=${1%.nc}
  name2=${1%/*}/isentropes_ncl
  np=0
  pmax=1000
  nsplit=10
  ts=$(command ncdump -h ${name1}.nc | grep 'UNLIMITED' | sed 's/[^0-9]//g') # number of timesteps
  # for t in $(seq 0 $((ts - 1))); do
  for ni in $(seq 1 $nsplit); do
    let np+=1
    t1=$(((ni - 1)*ts/nsplit)) # e.g. nsplit=10, ts=200, goes 0, 20, 40, 60
    t2=$((ni*ts/nsplit - 1)) # e.g. nsplit=10, ts=200, goes 19, 39, 59
    {
    # ncks -O -h --no-abc -d time,$t,$t ${name1}.nc ${name1}-${t}.nc
    # ncl -Q -n "filename=\"${name1}-${t}.nc\"" "outname=\"${name2}-${t}.nc\"" ${name}.ncl
    ncks -O -h --no-abc -d time,$t1,$t2 ${name1}.nc ${name1}-${ni}.nc
    ncl -Q -n "filename=\"${name1}-${ni}.nc\"" "outname=\"${name2}-${ni}.nc\"" ${name}.ncl
    } &
    [ $((np % pmax)) -eq 0 ] && wait
  done
  wait
  glob1=$name1'-*.nc'
  glob2=$name2'-*.nc'
  ncrcat -O $glob2 ${name2}_parallel.nc
  rm $glob1 $glob2
}

# Loop over datasets with different resolutions
type gdu &>/dev/null && cmd=gdu || cmd=du # need GNU utils version on mac
rm $dir/*-*.nc 2>/dev/null # remove parallel-prodcued files
datas=($dir/data*.nc)
counter=0
for data in ${datas[@]}; do
  # Header
  # NOTE: The 'disk usage' often very different from the 'apparent size'
  # ls -l; former depends on internals of how data is stored, and on Cheyenne,
  # ends up way bigger. See: https://unix.stackexchange.com/a/106278/112647
  # Explanation of why this happens: https://serverfault.com/a/290091/427991
  size=$($cmd --apparent-size -h $data | xargs | cut -d' ' -f1)
  version=${data%.nc}
  version=${version#*_}
  nlat=${data#*N}
  nlat=$(printf '%.0f' ${nlat%T*})
  echo; echo "Dataset: $data ($size)"
  printf "\n$header" >>$output # add header for each new file
  # sleep 3

  # NCL method
  # NOTE: NCL needs special dyld library path but so does brew, screws
  # up Homebrew if we set it, so set it locally
  export DYLD_LIBRARY_PATH="/usr/local/lib/gcc/4.9"
  bench "NCL" ncl -Q -n "filename=\"$data\"" "outname=\"${data%/*}/isentropes_ncl.nc\"" ${name}.ncl

  # NCL in parallel by splitting timesteps with ncks
  bench "NCL Parallel" ncl_parallel "$data"
  export DYLD_LIBRARY_PATH=""

  # Python with MetPy method
  bench "MetPy" python ${name}.py $data 0

  # Python with MetPy method
  bench "MetPy + Dask" python ${name}.py $data 10
done
