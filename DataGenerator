#!/usr/bin/env python3
# Generate random datasets with xarray and Dask, easiest way
# Then can test some very simple operations across several different methods
import os
import numpy as np
import dask.array as da
import xarray as xr
import datetime
import sys

# Check
try:
    reso = float(sys.argv[-1])
except ValueError:
    raise ValueError('Must pass grid resolution convertible to float.')
print(f'Resolution: {reso}')

# Dimensions
print('Initial stuff.')
dir = '60lev'
dtype = np.float32
step = 2
if dir=='1lev':
    ntime = 1000
    plev = np.array([500.0], dtype=dtype)
elif dir=='60lev':
    ntime = 200
    plev = np.linspace(0, 1013.25, 61, dtype=dtype)
    plev = (plev[1:] + plev[:-1])/2
else:
    raise ValueError('Unknown data dir {dir}.')
time = np.arange(1/step, ntime, dtype=dtype)/step
lat = np.arange(-90 + reso/2, 90, reso, dtype=dtype)
lon = np.arange(-180 + reso/2, 180, reso, dtype=dtype)
# Variables
shape = (time.size, plev.size, lat.size, lon.size)
params = ('u', 'v', 't')
params_attrs = {
    'u': {'long_name':'zonal wind', 'units':'m/s'},
    'v': {'long_name':'meridional wind', 'units':'m/s'},
    't': {'long_name':'temperature', 'units':'K'}
    }
# Coordinates
coords = ('time', 'plev', 'lat', 'lon')
coords_values = {
    'time': time,
    'plev': plev,
    'lat': lat,
    'lon': lon,
    }
coords_attrs = {
    'time': {'long_name':'time', 'calendar':'360_day', 'units':'days since 00-01-01 00:00:00', 'axis':'T'},
    'plev': {'long_name':'pressure level', 'units':'hPa', 'axis':'Z'},
    'lat': {'long_name':'latitude',  'units':'degN', 'axis':'Y'},
    'lon': {'long_name':'longitude', 'units':'degE', 'axis':'X'},
    }
for attrs in coords_attrs.values():
    attrs['standard_name'] = attrs['long_name']

# Variable data
# Numpy is extremely slow at making tons of random variables, so need to
# use dask so generation is done in parallel and we don't get memory overload
# NOTE: Random routines (including numpy ones) don't accept chunks.
# NOTE: If get overlapping contours, seems NCL handles these fine but metpy
# method has many issues. Just make zonally uniform fields.
print('Making variables.')
# chunks = (1, 1, *shape[2:]) # one chunk per horizontal slice, works for bigger datasets
# chunks = (1, shape[1], shape[2], shape[3]) # one chunk per timestep worked *way* better
# chunks = (1, shape[1]//4, shape[2], shape[3]) # compromise?
N = 100000
chunks = (1, N, N, N) # chunk in time dimension
# Temperature
base = da.zeros((time.size, 1, 1, lon.size), chunks=chunks) # empty array
offset = ((200 + 0.115*plev)[:,None,None] # max average of 200 + 115 = 315K
        - (60*np.abs(lat)/90)[:,None]) # average of 315 - 60 = 255K at pole
# Other
# NOTE: Got weird error when trying to use same Dask array for two variables,
# ended up with all NaNs
random1 = da.random.normal(0, 1, (time.size, 1, 1, lon.size), chunks=chunks).astype(dtype) # remember 2/3 fall within +/-1stdev
random1 = random1.cumsum(axis=0) + np.tile(0, (plev.size, lat.size, 1))
random2 = da.random.normal(0, 1, (time.size, 1, 1, lon.size), chunks=chunks).astype(dtype) # remember 2/3 fall within +/-1stdev
random2 = random2.cumsum(axis=0) + np.tile(0, (plev.size, lat.size, 1))
# Write variables
params_values = {'t':offset + base, 'u':random1, 'v':random2}
params_map = {name: (coords, params_values[name], params_attrs[name]) for name in params}
coords_map = {name: ((name,), coords_values[name], coords_attrs[name]) for name in coords}
print('Making dataset.')
data = xr.Dataset(params_map, coords_map)
for param in data.variables.values():
    param.encoding.update({'_FillValue':None}) # disable default fill value
# Below is too complex for Dask arrays; just accept this weird discontinuity
# random[...,:lon.size//2] = random[...,:lon.size//2].cumsum(axis=3)
# random[...,lon.size//2:] = random[...,lon.size//2-1::-1]

# Save
# NOTE: NaN encoding causes issues with NCO
# Diabled follwoing instructions here: http://xarray.pydata.org/en/stable/io.html
# NOTE: Can reorder variables following directions here: https://github.com/pydata/xarray/issues/479
# For some reason coordinates not first by default
# NOTE: Try both NetCDF3 classic and NetCDF4. Xarray has good guide
# on difference, found here: http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_netcdf.html
# Hunch is that some tools may do much better with full NetCDF4.
# format = 'NETCDF3_CLASSIC'
format = 'NETCDF4' # may fail for some CDO versions, try to fix
formats = {3:'NETCDF3_CLASSIC', 4:'NETCDF4'}
formats = {3:'NETCDF3_CLASSIC'} # differences are minor and 'classic' is still everywhere, so let's just use this
for num,format in formats.items():
    out = f'{dir}/dataN{lat.size:04d}T{ntime}_{num}.nc'
    if os.path.exists(out):
        os.remove(out)
    print(f'Writing to {out}.')
    data[[*coords, *params]].to_netcdf(out, mode='w', format=format, unlimited_dims={'time':True})

